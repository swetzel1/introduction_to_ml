{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swetzel1/introduction_to_ml/blob/main/hw5/hw5_p2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EhhoSqeiRsm3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4dbad36-c0c8-403d-a471-eea65b77149c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "torch.set_printoptions(edgeitems=2, linewidth=75)\n",
        "import torch.optim as optim\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0SJ76QEdRsm6"
      },
      "outputs": [],
      "source": [
        "#import and preprocess housing dataset\n",
        "#read data from csv file\n",
        "file_path = '/content/drive/My Drive/Intro_to_ML/Datasets/Housing.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "#display(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#select required parameters\n",
        "varlist =  ['price', 'area', 'bedrooms', 'bathrooms', 'stories', 'parking']\n",
        "\n",
        "df = df[varlist]\n",
        "#df.head()"
      ],
      "metadata": {
        "id": "EmjpNTUBp9_c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "num_vars = ['area', 'bedrooms', 'bathrooms', 'stories', 'parking'] # don't normalize output\n",
        "\n",
        "df[num_vars] = scaler.fit_transform(df[num_vars])\n",
        "#df.head()"
      ],
      "metadata": {
        "id": "ZzKT5JsYq3DP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#shuffle and prepare split\n",
        "n_samples = df.shape[0]\n",
        "n_val = int(0.2 * n_samples) # 20/80 split\n",
        "shuffled_indices = torch.randperm(n_samples) #randomize\n",
        "train_indices = shuffled_indices[:-n_val]\n",
        "val_indices = shuffled_indices[-n_val:]\n",
        "\n",
        "\n",
        "#split training and validation set\n",
        "y = df.pop('price')\n",
        "y = y.to_numpy()\n",
        "x = df.to_numpy()\n",
        "\n",
        "#convert numpy to tensor\n",
        "x_train = torch.tensor(x[train_indices], dtype=torch.float32)\n",
        "y_train = torch.tensor(y[train_indices], dtype=torch.float32)\n",
        "x_val = torch.tensor(x[val_indices], dtype=torch.float32)\n",
        "y_val = torch.tensor(y[val_indices], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "TnzJOsWiYiZa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class linearRegression(torch.nn.Module):\n",
        "    def __init__(self, inputSize, outputSize):\n",
        "        super(linearRegression, self).__init__()\n",
        "        self.linear = torch.nn.Linear(inputSize, outputSize)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "vKAGSnyN3KIj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#try different learning rates\n",
        "\n",
        "inputDim = 5          # dim of x\n",
        "outputDim = 1         # dim of y\n",
        "epochs = 5001\n",
        "\n",
        "model = linearRegression(inputDim, outputDim)\n",
        "#criterion = torch.nn.MSELoss()\n",
        "\n",
        "validation_loss_history = []\n",
        "training_loss_history = []\n",
        "\n",
        "\n",
        "for lr in [0.0005, 0.001, 0.002, 0.005]: #learning rates for SGD\n",
        "#for lr in [0.001, 0.01, 0.1, 0.5]: #learning rates for Adam\n",
        "#for lr in [0.0005]:\n",
        "\n",
        "\n",
        "\n",
        "  print('Learning rate:', lr)\n",
        "\n",
        "  criterion = torch.nn.MSELoss()\n",
        "\n",
        "  #choose optimizer\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "  #optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    train_in = Variable(x_train)\n",
        "    train_label = Variable(y_train)\n",
        "    train_label = train_label.unsqueeze(1)\n",
        "\n",
        "    val_in = Variable(x_val)\n",
        "    val_label = Variable(y_val)\n",
        "    val_label = val_label.unsqueeze(1)\n",
        "\n",
        "\n",
        "    optimizer.zero_grad() #important\n",
        "    train_pred = model(train_in)#predict\n",
        "    loss = criterion(train_pred, train_label)#get train loss\n",
        "\n",
        "    with torch.no_grad():\n",
        "      val_pred = model(val_in)\n",
        "      val_loss = criterion(val_pred, val_label)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    #store loss and print\n",
        "    training_loss_history.append(loss.item())#store loss\n",
        "    validation_loss_history.append(val_loss.item())\n",
        "\n",
        "    if epoch % 500 == 0: #report loss every 500 epochs\n",
        "      print('Epoch %d, Training Loss %f, Validation Loss: %f' % (epoch, float(loss), float(val_loss)))\n",
        "\n",
        "\n",
        "\n",
        "  print('\\n')\n",
        "  #plt.plot(training_loss_history, label=\"Training loss\")\n",
        "  #plt.plot(validation_loss_history, label=\"Validation loss\")\n",
        "  #plt.xlabel(\"epochs\")\n",
        "  #plt.ylabel(\"MSE\")\n",
        "  #plt.legend()\n",
        "  #plt.title(lr)\n",
        "  #plt.show()\n",
        "\n",
        "  training_loss_history.clear()\n",
        "  validation_loss_history.clear()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQMD45ZNQOPa",
        "outputId": "e3f901f7-ba86-459b-9946-304555812283"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate: 0.0005\n",
            "Epoch 0, Training Loss 26660619419648.000000, Validation Loss: 24426695360512.000000\n",
            "Epoch 500, Training Loss 10432548962304.000000, Validation Loss: 9130343399424.000000\n",
            "Epoch 1000, Training Loss 4828047081472.000000, Validation Loss: 3908920410112.000000\n",
            "Epoch 1500, Training Loss 2807693836288.000000, Validation Loss: 2087158022144.000000\n",
            "Epoch 2000, Training Loss 2063351414784.000000, Validation Loss: 1461910896640.000000\n",
            "Epoch 2500, Training Loss 1785352945664.000000, Validation Loss: 1259320115200.000000\n",
            "Epoch 3000, Training Loss 1680252076032.000000, Validation Loss: 1202395807744.000000\n",
            "Epoch 3500, Training Loss 1639941144576.000000, Validation Loss: 1192668561408.000000\n",
            "Epoch 4000, Training Loss 1624182226944.000000, Validation Loss: 1196139741184.000000\n",
            "Epoch 4500, Training Loss 1617863507968.000000, Validation Loss: 1201801527296.000000\n",
            "Epoch 5000, Training Loss 1615244951552.000000, Validation Loss: 1206591422464.000000\n",
            "\n",
            "\n",
            "Learning rate: 0.001\n",
            "Epoch 0, Training Loss 1615241543680.000000, Validation Loss: 1206599548928.000000\n",
            "Epoch 500, Training Loss 1613604061184.000000, Validation Loss: 1212299476992.000000\n",
            "Epoch 1000, Training Loss 1613243744256.000000, Validation Loss: 1214669914112.000000\n",
            "Epoch 1500, Training Loss 1613149503488.000000, Validation Loss: 1215584141312.000000\n",
            "Epoch 2000, Training Loss 1613121716224.000000, Validation Loss: 1215924273152.000000\n",
            "Epoch 2500, Training Loss 1613113065472.000000, Validation Loss: 1216050233344.000000\n",
            "Epoch 3000, Training Loss 1613110050816.000000, Validation Loss: 1216108167168.000000\n",
            "Epoch 3500, Training Loss 1613109264384.000000, Validation Loss: 1216100433920.000000\n",
            "Epoch 4000, Training Loss 1613109002240.000000, Validation Loss: 1216097681408.000000\n",
            "Epoch 4500, Training Loss 1613108871168.000000, Validation Loss: 1216097288192.000000\n",
            "Epoch 5000, Training Loss 1613108740096.000000, Validation Loss: 1216096763904.000000\n",
            "\n",
            "\n",
            "Learning rate: 0.002\n",
            "Epoch 0, Training Loss 1613108740096.000000, Validation Loss: 1216096763904.000000\n",
            "Epoch 500, Training Loss 1613108871168.000000, Validation Loss: 1216122060800.000000\n",
            "Epoch 1000, Training Loss 1613108740096.000000, Validation Loss: 1216122060800.000000\n",
            "Epoch 1500, Training Loss 1613108871168.000000, Validation Loss: 1216122191872.000000\n",
            "Epoch 2000, Training Loss 1613108740096.000000, Validation Loss: 1216122191872.000000\n",
            "Epoch 2500, Training Loss 1613108740096.000000, Validation Loss: 1216122191872.000000\n",
            "Epoch 3000, Training Loss 1613108740096.000000, Validation Loss: 1216122191872.000000\n",
            "Epoch 3500, Training Loss 1613108740096.000000, Validation Loss: 1216122191872.000000\n",
            "Epoch 4000, Training Loss 1613108740096.000000, Validation Loss: 1216122191872.000000\n",
            "Epoch 4500, Training Loss 1613108740096.000000, Validation Loss: 1216122191872.000000\n",
            "Epoch 5000, Training Loss 1613108740096.000000, Validation Loss: 1216122191872.000000\n",
            "\n",
            "\n",
            "Learning rate: 0.005\n",
            "Epoch 0, Training Loss 1613108740096.000000, Validation Loss: 1216122191872.000000\n",
            "Epoch 500, Training Loss 1613108740096.000000, Validation Loss: 1216137003008.000000\n",
            "Epoch 1000, Training Loss 1613108740096.000000, Validation Loss: 1216137003008.000000\n",
            "Epoch 1500, Training Loss 1613108740096.000000, Validation Loss: 1216137003008.000000\n",
            "Epoch 2000, Training Loss 1613108740096.000000, Validation Loss: 1216137003008.000000\n",
            "Epoch 2500, Training Loss 1613108740096.000000, Validation Loss: 1216137003008.000000\n",
            "Epoch 3000, Training Loss 1613108740096.000000, Validation Loss: 1216137003008.000000\n",
            "Epoch 3500, Training Loss 1613108740096.000000, Validation Loss: 1216137003008.000000\n",
            "Epoch 4000, Training Loss 1613108740096.000000, Validation Loss: 1216137003008.000000\n",
            "Epoch 4500, Training Loss 1613108740096.000000, Validation Loss: 1216137003008.000000\n",
            "Epoch 5000, Training Loss 1613108740096.000000, Validation Loss: 1216137003008.000000\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}